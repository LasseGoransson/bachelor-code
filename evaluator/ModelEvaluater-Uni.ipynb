{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "hWd-ciBPEyHS",
    "outputId": "20a8602b-838d-4b8b-da06-8e151757190b"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D,GlobalAveragePooling2D, Concatenate, Reshape,GlobalMaxPooling2D, Activation, Input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import IPython.display as display\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pathlib\n",
    "import datetime\n",
    "import math\n",
    "import sys\n",
    "import neptune\n",
    "\n",
    "def plotFromCsv(file):\n",
    "\n",
    "    data = np.genfromtxt(file, delimiter=',', skip_header=1, names=['epoch','loss','mse','val_loss','val_mse'])\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.plot(data['epoch'],data['val_loss'])\n",
    "    plt.plot(data['epoch'],data['loss'])\n",
    "    plt.title('Model accuracy (' +str(file)+\")\")\n",
    "    plt.ylabel('Loss (MSE) (KG)')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Validation Loss','Loss'], loc='upper right')\n",
    "    plt.ylim(0,0.8)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xrayPredictor\n",
    "xrayPredictor-448x448\n",
    "xrayPredictor-custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: It is not secure to place API token in your source code. You should treat it as a password to your account. It is strongly recommended to use NEPTUNE_API_TOKEN environment variable instead. Remember not to upload source file with API token to any public repository.\n"
     ]
    }
   ],
   "source": [
    "name = \"XRAY-162\"\n",
    "project = 'lassegoransson/xrayPredictor'\n",
    "import neptune\n",
    "key = \"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vdWkubmVwdHVuZS5haSIsImFwaV91cmwiOiJodHRwczovL3VpLm5lcHR1bmUuYWkiLCJhcGlfa2V5IjoiOWUxN2YwMTUtNjM1Ny00NmVlLWIzOTctNzAwYTllMGNmMTg2In0=\"\n",
    "project = neptune.init(project,api_token=key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  output.zip\n",
      "  inflating: output/model_resnet_aspect_baseline_3layer_l2reg.py_checkpoint-515x320-016-0.0029903836548328.hdf5  \n"
     ]
    }
   ],
   "source": [
    "!rm output/*\n",
    "ex = exp = project.get_experiments(name)[0]\n",
    "ex.download_artifacts()\n",
    "!unzip output.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['output/model_resnet_aspect_baseline_3layer_l2reg.py_checkpoint-515x320-016-0.0029903836548328.hdf5']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = !find output/ -name \"model*\"\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 818
    },
    "colab_type": "code",
    "id": "Te_i5QRxTAeo",
    "outputId": "76aae760-0a49-4ade-f353-1baa35231194"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_resnet_aspect_baseline_3layer_l2reg.py_checkpoint-515x320-016-0.0029903836548328.hdf5\n"
     ]
    }
   ],
   "source": [
    "modelname = files[0]\n",
    "modelpath = str(modelname.split(\"/\")[1])\n",
    "print(modelpath)\n",
    "model = tf.keras.models.load_model(modelname, custom_objects={'Activation': tf.keras.layers.Activation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "EDqUhHosFlqe",
    "outputId": "528f8e92-ff10-490d-b071-579dc9eae886"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "515\n",
      "320\n",
      "/home/lasg/bachelor-data/data_aspect_320\n",
      "Found 806 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "image_height = model.input_shape[1]\n",
    "image_width = model.input_shape[2]\n",
    "print(image_height)\n",
    "print(image_width)\n",
    "\n",
    "img = !head -n2 ~/bachelor-data/allTest.csv\n",
    "img = img[1].split(\",\")[0]\n",
    "imgdir=\"\"\n",
    "posDir = ! find ~/bachelor-data/ -maxdepth 1 -type d -not -path *checkpoints* -not -path /home/lasg/bachelor-data/\n",
    "for folder in posDir:\n",
    "    imgf = Image.open(folder+\"/\"+img)\n",
    "    \n",
    "    if (imgf.height == image_height and imgf.width == image_width):\n",
    "        imgdir = folder\n",
    "\n",
    "print(imgdir)\n",
    "\n",
    "test_df = pandas.read_csv(\"/home/lasg/bachelor-data/allTest.csv\")\n",
    "test_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        )\n",
    "\n",
    "shape = model.input_shape\n",
    "height = shape[1]\n",
    "width = shape[2]\n",
    "\n",
    "if model.input_shape[3] == 1:\n",
    "    \n",
    "    test_generator = test_datagen.flow_from_dataframe(\n",
    "            dataframe=test_df,\n",
    "            directory=imgdir,\n",
    "            x_col=\"filename\",\n",
    "            y_col='label',\n",
    "            target_size=(image_height, image_width),\n",
    "            batch_size=1,\n",
    "            shuffle=False,\n",
    "            class_mode=\"raw\",\n",
    "            color_mode=\"grayscale\"\n",
    "            #color_mode=\"rgb\"\n",
    "            )\n",
    "else: \n",
    "        test_generator = test_datagen.flow_from_dataframe(\n",
    "            dataframe=test_df,\n",
    "            directory=imgdir,\n",
    "            x_col=\"filename\",\n",
    "            y_col='label',\n",
    "            target_size=(image_height, image_width),\n",
    "            batch_size=1,\n",
    "            shuffle=False,\n",
    "            class_mode=\"raw\",\n",
    "            #color_mode=\"grayscale\"\n",
    "            color_mode=\"rgb\"\n",
    "            )\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UnDLU9gjD5gD"
   },
   "source": [
    "# Evaluate\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31.1414392059553366"
     ]
    }
   ],
   "source": [
    "n = []\n",
    "nnon=[]\n",
    "mse=0\n",
    "hits=[0,0,0,0,0,0]\n",
    "labeltrueVal = 0\n",
    "labelval = 0\n",
    "i=0\n",
    "for b in range(0,test_generator.n):\n",
    "  img,y= test_generator.next()\n",
    "  img=img[0]\n",
    "  sys.stdout.write(\"\\r\" + str(100*i/test_generator.n))\n",
    "  label = y[0]\n",
    "  predict = model.predict(np.expand_dims(img, axis=0))[0][0]\n",
    "  val =(1-(label/predict))\n",
    "  mse+=((1/test_generator.n)*(label-predict)*(label-predict))\n",
    "  nnon.append(val)\n",
    "  val=abs(val)\n",
    "  n.append(val)\n",
    "  if val < 0.05:\n",
    "    hits[0] += 1\n",
    "  if val < 0.10:\n",
    "    hits[1] += 1\n",
    "  if val < 0.15:\n",
    "    hits[2] += 1\n",
    "  if val < 0.20:\n",
    "    hits[3] += 1\n",
    "  if val < 0.25:\n",
    "    hits[4] += 1\n",
    "  if val < 0.30:\n",
    "    hits[5] += 1\n",
    "\n",
    "  #BATCH\n",
    "  labeltrueVal += label\n",
    "  labelval +=predict\n",
    "  i+=1\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelname.split(\"/\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 769
    },
    "colab_type": "code",
    "id": "alp2Sx9uDv5E",
    "outputId": "6e7e4df2-0f3f-44a0-c1b3-3781c04c53a7",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"\")\n",
    "print(\"MSE: \"+str(mse))\n",
    "print(\"\")\n",
    "print(\"Deviation from true weight (< 5% = 90 is project goal)\")\n",
    "print(\"< 5.0% = \" +  str(100*hits[0]/(test_generator.n))+ \"%\")\n",
    "print(\"< 10.0% = \" + str(100*hits[1]/(test_generator.n))+ \"%\")\n",
    "print(\"< 15.0% = \" + str(100*hits[2]/(test_generator.n))+ \"%\")\n",
    "print(\"< 20.0% = \" + str(100*hits[3]/(test_generator.n))+ \"%\")\n",
    "print(\"< 25.0% = \" + str(100*hits[4]/(test_generator.n))+ \"%\")\n",
    "print(\"< 30.0% = \" + str(100*hits[5]/(test_generator.n))+ \"%\")\n",
    "print(\"\")\n",
    "print(\"Deviation summed over full batch\")\n",
    "print(\"Predicted weight: \"+str(labelval)+\" True weight: \"+str(labeltrueVal)+\" Percentage: \"+str((labelval/labeltrueVal)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex.log_metric(\"5%_score\",100*hits[0]/(test_generator.n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.stem(range(0,len(n)),nnon,use_line_collection=True)\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.xlabel('N of test')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ModelEvaluater.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
